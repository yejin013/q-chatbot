import streamlit as st
import requests
import json
from datetime import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„ë² ë”© í…ŒìŠ¤íŠ¸",
    page_icon="ğŸ§ª",
    layout="wide"
)

# API ê¸°ë³¸ URL
API_BASE_URL = "http://localhost:8000"

def test_embedding_with_file(file, question, model_names):
    """íŒŒì¼ë¡œ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    try:
        files = {"file": file}
        data = {
            "question": question,
            "model_names": model_names
        }
        response = requests.post(
            f"{API_BASE_URL}/embedding-test/test-with-file",
            files=files,
            data=data
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def test_embedding_with_text(question, model_names):
    """í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
    try:
        data = {
            "question": question,
            "model_names": model_names
        }
        response = requests.post(f"{API_BASE_URL}/embedding-test/test-with-text", json=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{API_BASE_URL}/embedding-test/available-models")
        
        if response.status_code == 200:
            return response.json()["data"]
        else:
            st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.text}")
            return {}
    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}

def get_test_history():
    """í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        response = requests.get(f"{API_BASE_URL}/embedding-test/history")
        
        if response.status_code == 200:
            return response.json()["data"]
        else:
            st.error(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {response.text}")
            return []
    except Exception as e:
        st.error(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

# ë©”ì¸ UI
st.title("ğŸ§ª ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
st.markdown("ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³  í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´
st.header("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸")
models_info = get_available_models()

if models_info:
    # ëª¨ë¸ ì •ë³´ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
    model_data = []
    for model_name, info in models_info.items():
        model_data.append({
            "ëª¨ë¸ëª…": model_name,
            "ì°¨ì›": info.get("dimension", "N/A"),
            "ì‚¬ìš© ê°€ëŠ¥": "âœ…" if info.get("available", False) else "âŒ"
        })
    
    df_models = pd.DataFrame(model_data)
    st.dataframe(df_models, use_container_width=True, hide_index=True)
else:
    st.warning("ëª¨ë¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í…ŒìŠ¤íŠ¸ ì„¹ì…˜
st.header("ğŸ”¬ ì„ë² ë”© í…ŒìŠ¤íŠ¸")

# í…ŒìŠ¤íŠ¸ ë°©ë²• ì„ íƒ
test_method = st.radio(
    "í…ŒìŠ¤íŠ¸ ë°©ë²• ì„ íƒ",
    ["íŒŒì¼ ì—…ë¡œë“œ", "ìƒ˜í”Œ í…ìŠ¤íŠ¸"],
    help="íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¯¸ë¦¬ ì •ì˜ëœ ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ëª¨ë¸ ì„ íƒ
available_models = [name for name, info in models_info.items() if info.get("available", False)]
if available_models:
    selected_models = st.multiselect(
        "í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ì„ íƒ",
        options=available_models,
        default=available_models[:3] if len(available_models) >= 3 else available_models,
        help="ë¹„êµí•  ì„ë² ë”© ëª¨ë¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš”."
    )
else:
    st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    selected_models = []

# ì§ˆë¬¸ ì…ë ¥
question = st.text_area(
    "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì…ë ¥",
    value="ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    height=80,
    help="ì„ë² ë”© ëª¨ë¸ë“¤ì´ ì°¾ì„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."
)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if test_method == "íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader(
        "í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ì—…ë¡œë“œ",
        type=["pdf", "docx"],
        help="PDF ë˜ëŠ” DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”."
    )
    
    if uploaded_file and selected_models and st.button("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary"):
        with st.spinner("ì„ë² ë”© ëª¨ë¸ë“¤ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¤‘..."):
            result = test_embedding_with_file(uploaded_file, question, selected_models)
            
            if result and result.get("success"):
                display_test_results(result["data"])
            else:
                st.error("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

else:  # ìƒ˜í”Œ í…ìŠ¤íŠ¸
    if selected_models and st.button("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary"):
        with st.spinner("ì„ë² ë”© ëª¨ë¸ë“¤ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¤‘..."):
            result = test_embedding_with_text(question, selected_models)
            
            if result and result.get("success"):
                display_test_results(result["data"])
            else:
                st.error("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

def display_test_results(data):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ"""
    st.success("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    # ê²°ê³¼ ìš”ì•½
    st.subheader("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    
    results = data["results"]
    successful_models = [name for name, result in results.items() if result.get("status") == "success"]
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("í…ŒìŠ¤íŠ¸ ëª¨ë¸ ìˆ˜", len(selected_models))
    with col2:
        st.metric("ì„±ê³µí•œ ëª¨ë¸ ìˆ˜", len(successful_models))
    with col3:
        success_rate = len(successful_models) / len(selected_models) * 100 if selected_models else 0
        st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
    
    # ê° ëª¨ë¸ë³„ ê²°ê³¼
    st.subheader("ğŸ” ëª¨ë¸ë³„ ìƒì„¸ ê²°ê³¼")
    
    for model_name, result in results.items():
        with st.expander(f"ğŸ“ˆ {model_name}"):
            if result.get("status") == "success":
                model_results = result.get("results", [])
                
                if model_results:
                    # ìœ ì‚¬ë„ ì ìˆ˜ ì°¨íŠ¸
                    similarities = [r["similarity"] for r in model_results]
                    indices = [r["index"] for r in model_results]
                    
                    # ì°¨íŠ¸ ìƒì„±
                    fig = go.Figure(data=[
                        go.Bar(
                            x=[f"ê²°ê³¼ {i+1}" for i in range(len(similarities))],
                            y=similarities,
                            text=[f"{s:.3f}" for s in similarities],
                            textposition='auto',
                            name="ìœ ì‚¬ë„ ì ìˆ˜"
                        )
                    ])
                    
                    fig.update_layout(
                        title=f"{model_name} - ìœ ì‚¬ë„ ì ìˆ˜ ë¹„êµ",
                        xaxis_title="ê²€ìƒ‰ ê²°ê³¼",
                        yaxis_title="ìœ ì‚¬ë„ ì ìˆ˜",
                        yaxis_range=[0, 1]
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
                    st.write("**ìƒì„¸ ê²°ê³¼:**")
                    for i, r in enumerate(model_results):
                        st.write(f"**ê²°ê³¼ {i+1}** (ìœ ì‚¬ë„: {r['similarity']:.3f})")
                        st.write(f"ë‚´ìš©: {r['content'][:200]}...")
                        st.divider()
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error(f"ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    # ëª¨ë¸ ë¹„êµ ì°¨íŠ¸
    if len(successful_models) > 1:
        st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        
        # í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        model_avg_similarities = {}
        for model_name in successful_models:
            model_results = results[model_name].get("results", [])
            if model_results:
                avg_similarity = sum(r["similarity"] for r in model_results) / len(model_results)
                model_avg_similarities[model_name] = avg_similarity
        
        if model_avg_similarities:
            # í‰ê·  ìœ ì‚¬ë„ ë¹„êµ ì°¨íŠ¸
            fig_comparison = px.bar(
                x=list(model_avg_similarities.keys()),
                y=list(model_avg_similarities.values()),
                title="ëª¨ë¸ë³„ í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ ë¹„êµ",
                labels={"x": "ëª¨ë¸", "y": "í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜"}
            )
            
            fig_comparison.update_layout(yaxis_range=[0, 1])
            st.plotly_chart(fig_comparison, use_container_width=True)

# í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬
st.header("ğŸ“š í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬")

# ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
if st.button("ğŸ”„ íˆìŠ¤í† ë¦¬ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

# íˆìŠ¤í† ë¦¬ ì¡°íšŒ
history = get_test_history()

if history:
    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
    df_history = pd.DataFrame(history)
    df_history["ìƒì„± ë‚ ì§œ"] = pd.to_datetime(df_history["created_at"]).dt.strftime("%Y-%m-%d %H:%M")
    
    # í‘œì‹œí•  ì»¬ëŸ¼ë§Œ ì„ íƒ
    display_df = df_history[["question", "model_name", "ìƒì„± ë‚ ì§œ"]].copy()
    display_df.columns = ["ì§ˆë¬¸", "ëª¨ë¸", "ìƒì„± ë‚ ì§œ"]
    
    # ì§ˆë¬¸ ê¸¸ì´ ì œí•œ
    display_df["ì§ˆë¬¸"] = display_df["ì§ˆë¬¸"].apply(lambda x: x[:50] + "..." if len(x) > 50 else x)
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True
    )
    
    # í†µê³„ ì •ë³´
    st.subheader("ğŸ“Š íˆìŠ¤í† ë¦¬ í†µê³„")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ í…ŒìŠ¤íŠ¸ ìˆ˜", len(history))
    with col2:
        recent_tests = len([h for h in history if "2024" in h["created_at"]])  # ê°„ë‹¨í•œ ìµœê·¼ í•„í„°
        st.metric("ìµœê·¼ í…ŒìŠ¤íŠ¸", recent_tests)
    with col3:
        unique_models = len(set(h["model_name"] for h in history))
        st.metric("ì‚¬ìš©ëœ ëª¨ë¸", unique_models)
        
else:
    st.info("ğŸ“ ì•„ì§ í…ŒìŠ¤íŠ¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!")

# ì‚¬ì´ë“œë°”ì— ë„ì›€ë§
with st.sidebar:
    st.header("ğŸ’¡ ë„ì›€ë§")
    st.markdown("""
    **ì„ë² ë”© í…ŒìŠ¤íŠ¸ë€?**
    - ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤
    - ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ê° ëª¨ë¸ì´ ì°¾ëŠ” ê²°ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    
    **í…ŒìŠ¤íŠ¸ ë°©ë²•:**
    1. íŒŒì¼ ì—…ë¡œë“œ: ì‹¤ì œ ë¬¸ì„œë¡œ í…ŒìŠ¤íŠ¸
    2. ìƒ˜í”Œ í…ìŠ¤íŠ¸: ë¯¸ë¦¬ ì •ì˜ëœ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
    
    **ê²°ê³¼ í•´ì„:**
    - ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ë” ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼
    - ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ë³´ì¼ ìˆ˜ ìˆìŒ
    - ìš©ë„ì— ë§ëŠ” ëª¨ë¸ ì„ íƒì´ ì¤‘ìš”
    
    **ëª¨ë¸ íŠ¹ì„±:**
    - **OpenAI Ada**: ë¹ ë¥´ê³  ì•ˆì •ì 
    - **BGE**: ë†’ì€ ì •í™•ë„
    - **MiniLM**: ë¹ ë¥¸ ì†ë„
    - **Cohere**: ê· í˜•ì¡íŒ ì„±ëŠ¥
    """)
    
    # ìƒ˜í”Œ ì§ˆë¬¸ë“¤
    st.header("ğŸ’­ ìƒ˜í”Œ ì§ˆë¬¸")
    sample_questions = [
        "ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì£¼ìš” ê²°ë¡ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì´ ë¬¸ì„œì—ì„œ ë‹¤ë£¨ëŠ” ë¬¸ì œì ì€?",
        "í•´ê²° ë°©ì•ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    for i, q in enumerate(sample_questions):
        if st.button(q, key=f"sample_{i}"):
            st.session_state.sample_question = q
            st.rerun() 