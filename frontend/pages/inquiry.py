import streamlit as st
import requests
import json
from datetime import datetime
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì§ˆì˜ì‘ë‹µ",
    page_icon="â“",
    layout="wide"
)

# API ê¸°ë³¸ URL
API_BASE_URL = "http://localhost:8000"

def ask_question(question, model_name="text-embedding-ada-002"):
    """ì§ˆë¬¸ API í˜¸ì¶œ"""
    try:
        data = {
            "question": question,
            "model_name": model_name
        }
        response = requests.post(f"{API_BASE_URL}/qa/ask", json=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {response.text}")
            return None
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def update_feedback(answer_id, is_positive):
    """í”¼ë“œë°± ì—…ë°ì´íŠ¸"""
    try:
        data = {"is_positive": is_positive}
        response = requests.patch(f"{API_BASE_URL}/qa/answers/{answer_id}", json=data)
        
        if response.status_code == 200:
            return True
        else:
            st.error(f"í”¼ë“œë°± ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {response.text}")
            return False
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def get_qa_history():
    """ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        response = requests.get(f"{API_BASE_URL}/qa/history")
        
        if response.status_code == 200:
            return response.json()["data"]
        else:
            st.error(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {response.text}")
            return []
    except Exception as e:
        st.error(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

# ë©”ì¸ UI
st.title("â“ AI ì§ˆì˜ì‘ë‹µ")
st.markdown("ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  AIì˜ ë‹µë³€ì„ ë°›ì•„ë³´ì„¸ìš”.")

# ì§ˆë¬¸ ì…ë ¥ ì„¹ì…˜
st.header("ì§ˆë¬¸í•˜ê¸°")

# ì„ë² ë”© ëª¨ë¸ ì„ íƒ
model_options = {
    "text-embedding-ada-002": "OpenAI Ada (ê¸°ë³¸)",
    "BAAI/bge-base-en-v1.5": "BGE Base",
    "sentence-transformers/all-MiniLM-L6-v2": "MiniLM",
    "cohere-embed-v3": "Cohere V3"
}

selected_model = st.selectbox(
    "ì„ë² ë”© ëª¨ë¸ ì„ íƒ",
    options=list(model_options.keys()),
    format_func=lambda x: model_options[x],
    help="ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ì§ˆë¬¸ ì…ë ¥
question = st.text_area(
    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
    placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    height=100,
    help="ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”."
)

# ì§ˆë¬¸ ì œì¶œ
if st.button("ğŸ” ì§ˆë¬¸í•˜ê¸°", type="primary", disabled=not question.strip()):
    if question.strip():
        with st.spinner("ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            result = ask_question(question, selected_model)
            
            if result and result.get("success"):
                data = result["data"]
                
                # ë‹µë³€ í‘œì‹œ
                st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")
                
                # ë‹µë³€ ë‚´ìš©
                st.subheader("ğŸ¤– AI ë‹µë³€")
                st.write(data["answer"])
                
                # ê´€ë ¨ ë¬¸ì„œ ì •ë³´
                if data.get("relevant_documents"):
                    st.subheader("ğŸ“„ ê´€ë ¨ ë¬¸ì„œ")
                    for i, doc in enumerate(data["relevant_documents"], 1):
                        with st.expander(f"ë¬¸ì„œ {i}: {doc['filename']} (ìœ ì‚¬ë„: {doc['similarity']:.3f})"):
                            st.write(doc["content_preview"])
                
                # í”¼ë“œë°± ë²„íŠ¼
                st.subheader("ğŸ’¬ ë‹µë³€ í‰ê°€")
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ‘ ì¢‹ì•„ìš”", key="positive"):
                        if update_feedback(data["answer_id"], True):
                            st.success("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                with col2:
                    if st.button("ğŸ‘ ê°œì„  í•„ìš”", key="negative"):
                        if update_feedback(data["answer_id"], False):
                            st.success("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ì„¸ì…˜ì— ìµœê·¼ ë‹µë³€ ì €ì¥
                if "recent_answers" not in st.session_state:
                    st.session_state.recent_answers = []
                
                st.session_state.recent_answers.insert(0, {
                    "question": data["question"],
                    "answer": data["answer"],
                    "model": selected_model,
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
                
                # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
                st.session_state.recent_answers = st.session_state.recent_answers[:5]
            else:
                st.error("âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨")

# ìµœê·¼ ë‹µë³€ í‘œì‹œ
if "recent_answers" in st.session_state and st.session_state.recent_answers:
    st.header("ğŸ•’ ìµœê·¼ ë‹µë³€")
    
    for i, qa in enumerate(st.session_state.recent_answers):
        with st.expander(f"Q: {qa['question'][:50]}... ({qa['timestamp']})"):
            st.write(f"**ì§ˆë¬¸:** {qa['question']}")
            st.write(f"**ëª¨ë¸:** {model_options.get(qa['model'], qa['model'])}")
            st.write(f"**ë‹µë³€:** {qa['answer']}")

# ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬
st.header("ğŸ“š ì§ˆì˜ì‘ë‹µ íˆìŠ¤í† ë¦¬")

# ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
if st.button("ğŸ”„ íˆìŠ¤í† ë¦¬ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

# íˆìŠ¤í† ë¦¬ ì¡°íšŒ
history = get_qa_history()

if history:
    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
    df = pd.DataFrame(history)
    df["ìƒì„± ë‚ ì§œ"] = pd.to_datetime(df["created_at"]).dt.strftime("%Y-%m-%d %H:%M")
    df["í”¼ë“œë°±"] = df["is_positive"].apply(lambda x: "ğŸ‘" if x else "ğŸ‘" if x is False else "â“")
    
    # í‘œì‹œí•  ì»¬ëŸ¼ë§Œ ì„ íƒ
    display_df = df[["question", "answer", "í”¼ë“œë°±", "ìƒì„± ë‚ ì§œ"]].copy()
    display_df.columns = ["ì§ˆë¬¸", "ë‹µë³€", "í”¼ë“œë°±", "ìƒì„± ë‚ ì§œ"]
    
    # ì§ˆë¬¸ê³¼ ë‹µë³€ ê¸¸ì´ ì œí•œ
    display_df["ì§ˆë¬¸"] = display_df["ì§ˆë¬¸"].apply(lambda x: x[:50] + "..." if len(x) > 50 else x)
    display_df["ë‹µë³€"] = display_df["ë‹µë³€"].apply(lambda x: x[:100] + "..." if len(x) > 100 else x)
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True
    )
    
    # í†µê³„ ì •ë³´
    st.subheader("ğŸ“Š íˆìŠ¤í† ë¦¬ í†µê³„")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ì§ˆë¬¸ ìˆ˜", len(history))
    with col2:
        positive_count = len([h for h in history if h["is_positive"] is True])
        st.metric("ê¸ì • í”¼ë“œë°±", positive_count)
    with col3:
        negative_count = len([h for h in history if h["is_positive"] is False])
        st.metric("ë¶€ì • í”¼ë“œë°±", negative_count)
    with col4:
        feedback_rate = (positive_count + negative_count) / len(history) * 100 if history else 0
        st.metric("í”¼ë“œë°± ë¹„ìœ¨", f"{feedback_rate:.1f}%")
        
else:
    st.info("ğŸ“ ì•„ì§ ì§ˆì˜ì‘ë‹µ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# ì‚¬ì´ë“œë°”ì— ë„ì›€ë§
with st.sidebar:
    st.header("ğŸ’¡ ë„ì›€ë§")
    st.markdown("""
    **ì§ˆë¬¸ íŒ:**
    - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì„ í•˜ì„¸ìš”
    - ë¬¸ì„œì˜ íŠ¹ì • ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”
    - "ì´ ë¬¸ì„œì—ì„œ ~ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”" í˜•ì‹ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”
    
    **ì„ë² ë”© ëª¨ë¸:**
    - **OpenAI Ada**: ë¹ ë¥´ê³  ì•ˆì •ì  (ê¸°ë³¸)
    - **BGE Base**: ë†’ì€ ì •í™•ë„
    - **MiniLM**: ë¹ ë¥¸ ì†ë„
    - **Cohere V3**: ê· í˜•ì¡íŒ ì„±ëŠ¥
    
    **í”¼ë“œë°±:**
    - ë‹µë³€ í’ˆì§ˆì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”
    - í”¼ë“œë°±ì€ ì‹œìŠ¤í…œ ê°œì„ ì— ë„ì›€ì´ ë©ë‹ˆë‹¤
    """)
    
    # ëª¨ë¸ ì •ë³´
    st.header("ğŸ”§ ëª¨ë¸ ì •ë³´")
    model_info = {
        "text-embedding-ada-002": "ì°¨ì›: 1536, ì†ë„: ë¹ ë¦„, ì •í™•ë„: ì¤‘ìƒ",
        "BAAI/bge-base-en-v1.5": "ì°¨ì›: 768, ì†ë„: ì¤‘ê°„, ì •í™•ë„: ë†’ìŒ",
        "sentence-transformers/all-MiniLM-L6-v2": "ì°¨ì›: 384, ì†ë„: ë¹ ë¦„, ì •í™•ë„: ë‚®ìŒ",
        "cohere-embed-v3": "ì°¨ì›: 1024, ì†ë„: ë¹ ë¦„, ì •í™•ë„: ì¤‘ìƒ"
    }
    
    for model, info in model_info.items():
        if model in model_options:
            st.caption(f"**{model_options[model]}**")
            st.caption(info) 